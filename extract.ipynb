{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options as ChromeOptions\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = ChromeOptions()\n",
    "chrome_options.add_argument(\"--headless=new\")\n",
    "main_df = pd.DataFrame(columns = [\"Stadium\", \"Capacity\", \"Spectators\", \"Average\",\t\"Matches\", \"sold out\", \"Capacity\", \"Club\", \"Year\"])\n",
    "seasons = [2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023]\n",
    "leagues_prefixs = [\"SA1\", \"SA2L\"]\n",
    "dfs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_attendences():\n",
    "  for i in range(len(seasons)):\n",
    "    url = f'https://www.transfermarkt.com/saudi-pro-league/besucherzahlen/wettbewerb/SA1/saison_id/{seasons[i]}/plus/1'\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "    html = scrapingHTML(driver, i)\n",
    "    print(f'Season {seasons[i]} - Scraping done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NoSuchElementExceptionHandler function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NoSuchElementExceptionHandler(driver, ID, XPATH):\n",
    "  try:\n",
    "        WebDriverWait(driver, 10).until(EC.frame_to_be_available_and_switch_to_it(driver.find_element(By.ID, ID)))\n",
    "        driver.find_element(By.XPATH, XPATH).click()\n",
    "  except NoSuchElementException as exc:\n",
    "    pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get data with Selenium and BS4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapingHTML(driver, i):\n",
    "  NoSuchElementExceptionHandler(driver, \"sp_message_iframe_851946\", \"//*[@id='notice']/div[3]/div[3]/button\")\n",
    "\n",
    "  table = driver.find_element(By.XPATH, '//*[@id=\"yw1\"]/table')\n",
    "  data = table.get_attribute('outerHTML')\n",
    "  soup = BeautifulSoup(data, 'html.parser')\n",
    "  html = soup.find(name='table')\n",
    "  df = pd.read_html(str(html))[0]\n",
    "  df[\"Club\"] = \"\"\n",
    "  df[\"Year\"] = seasons[i]\n",
    "  dfs.append(df)\n",
    "  driver.quit()\n",
    "  return html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Teams info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teams_list_extract(league):\n",
    "  for i in range(len(league)):\n",
    "    url = f\"https://www.transfermarkt.us/saudi-pro-league/startseite/wettbewerb/{league[i]}\"\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "\n",
    "    NoSuchElementExceptionHandler(driver, \"sp_message_iframe_851946\", \"//*[@id='notice']/div[3]/div[3]/button\")\n",
    "\n",
    "    table = driver.find_element(By.XPATH, '//*[@id=\"yw1\"]/table')\n",
    "    data = table.get_attribute('outerHTML')\n",
    "    soup = BeautifulSoup(data, 'html.parser')\n",
    "    html = soup.find(name='table')\n",
    "    df = pd.read_html(str(html))[0]\n",
    "    df[\"League\"] = league[i]\n",
    "    df.to_csv(f\"./RAW/ArabicSoccer/Teams/{league[i]}_teams_2023.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract All Champions - SPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_champions(league):\n",
    "  for i in range(len(league)):\n",
    "    url = f\"https://www.transfermarkt.us/saudi-professional-league/erfolge/wettbewerb/{league[i]}\"\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "\n",
    "    NoSuchElementExceptionHandler(driver, \"sp_message_iframe_851946\", \"//*[@id='notice']/div[3]/div[3]/button\")\n",
    "    \n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(EC.frame_to_be_available_and_switch_to_it(driver.find_element(By.ID, \"sp_message_iframe_851946\")))\n",
    "        driver.find_element(By.XPATH,\"\").click()\n",
    "    except NoSuchElementException as exc:\n",
    "      pass\n",
    "\n",
    "    table = driver.find_element(By.XPATH, '//*[@id=\"yw1\"]/table')\n",
    "    data = table.get_attribute('outerHTML')\n",
    "    soup = BeautifulSoup(data, 'html.parser')\n",
    "    html = soup.find(name='table')\n",
    "    df = pd.read_html(str(html))[0]\n",
    "    if i == 1:\n",
    "      df[\"League\"] = \"Saudi Pro League\"\n",
    "    else:\n",
    "      df[\"League\"] = \"Yelo League\"\n",
    "    df.to_csv(f\"./RAW/ArabicSoccer/Champions/{league[i]}_Champions.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_champions(leagues_prefixs)\n",
    "extract_attendences()\n",
    "teams_list_extract(leagues_prefixs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat DataFrame list and create CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_og = pd.concat(dfs)\n",
    "df_og.to_csv(\"./RAW/ArabicSoccer/Attendances/Arabic_Attendances_2007_2023.csv\", encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
